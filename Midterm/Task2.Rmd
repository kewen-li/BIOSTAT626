---
title: "project Task2"
author: "Kewen Li"
date: "`r Sys.Date()`"
output: pdf_document
---
```{r,message=FALSE,warning=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(randomForest)
library(Boruta)
```

```{r}
training_data <- read.csv("~/Downloads/School/Umich/BIOSTAT 626/Project/Midterm/training_data.txt", sep="")
test_data <- read.csv("~/Downloads/School/Umich/BIOSTAT 626/Project/Midterm/test_data.txt", sep="")
```

# Multiple Classifier
## Revise the Response Variable
```{r}
change_value <- function(x) {
  if (x >= 7) {
    return(7)
  } else {
    return (x)
  }
}
training_data['class'] <- apply(training_data['activity'],1, change_value)
```


## split the data into training and testing sets
```{r}
set.seed(42)
split <- createDataPartition(training_data$class, p=0.8, list=FALSE)
X_train <- training_data[split, -c(1,2,564) ]
X_test <- training_data[-split, -c(1,2,564)]
y_train <- factor(training_data$class[split])
y_test <- factor(training_data$class[-split])
```

## Hand Select 
```{r}
#grid <- expand.grid(mtry = c(5, 10, 20, 50, 100, 200, 300, 400, 450, 475))
mtry_vals <- seq(from = 5, to = 50, by = 5)
#ntree_vals <- seq(from = 50, to = 500, by = 50)
param_grid <- expand.grid(.mtry = 10)
# Set up the cross-validation method and parameter grid for tuning
control <- trainControl(method = 'repeatedcv',
                        number = 10,
                        repeats = 3,
                        search = 'grid')
```


```{r}
set.seed(123)
modellist <- list()
#train with different ntree parameters
for (ntree in seq(from = 50, to = 500, by = 50)){
  fit <- train(X_train, y_train,
               method = 'rf',
               metric = 'Accuracy',
               tuneGrid = param_grid,
               trControl = control,
               ntree = ntree,verbose = TRUE)
  key <- toString(ntree)
  modellist[[key]] <- fit
}
#fit <- train(X_train, y_train, method="rf", trControl= control, tuneGrid = param_grid,verbose = TRUE)
```
```{r}
#Compare results
results <- resamples(modellist)
summary(results)
```
```{r}
dotplot(results)
```

```{r}
# Get the optimal hyperparameters
best_mtry <- fit$bestTune$mtry
best_ntree <- fit$bestTune$ntree
print(best_mtry,best_ntree)
```


```{r}
control <- trainControl(method='repeatedcv', 
                        number=10, 
                        repeats=3,
                        search = 'random')

set.seed(123)
modellist <- list()
for (ntree in seq(from = 10, to = 100, by = 10)){
print(paste0("Ntree ",ntree," started"))
  fit <- train(X_train, y_train,
               method = 'rf',
               metric = 'Accuracy',
               trControl = control,
               tuneLength  = 10,
                verbose = 1)
  key <- toString(ntree)
  modellist[[key]] <- fit
  print(paste0("Ntree ",ntree,"finished"))
}
```
```{r}
#n tree 10
  fit <- train(X_train, y_train,
               method = 'rf',
               metric = 'Accuracy',
               trControl = control,
               tuneLength  = 10,
               ntree=10)
  key <- toString(10)
  modellist[[key]] <- fit
```
```{r}
#Compare results
results <- resamples(modellist)
summary(results)
```
```{r}
dotplot(results)
```

```{r}
results
```
```{r}
modellist[2]
```
## feature selection
```{r}
# calculate variable importance scores
importance <- varImp(fit)

# select top 2 features based on importance scores
top_features <- row.names(importance$importance)[order(importance$importance$Overall, decreasing = TRUE)[1:500]]
top_features
```
```{r}
# fit model with top features only
fit_top <- train(X_train[, top_features], y_train, method = "rf", trControl = trainControl(method = "none"))
```



## Prediction
```{r}
# Using n tree =100, mtry =20
repGrid <- expand.grid(.mtry=c(20))  # no ntree
 best_fit <- train(X_train, y_train,
               method = 'rf',
               metric = 'Accuracy',
               trControl = trainControl(method='repeatedcv', 
                        number=10, 
                        repeats=3),
               tuneGrid = repGrid,
               ntree=100)
```

```{r}
y_pred <- predict(modellist[[2]], X_test)
confusionMatrix(y_pred, y_test)
```

```{r}
multi_prediction <- predict(fit, test_data[,-1])
multi_results_df <- data.frame(multi_prediction)
multi_prediction
```



## Expore TXT File
```{r}
write.table(multi_results_df, "multiclass_k5484.txt", sep="\t", quote = FALSE, row.names=FALSE,col.names=FALSE)
```
